{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656acfde",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac8381f-4baa-4827-8163-db4aec88a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.1.2 in /opt/conda/lib/python3.8/site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision==0.16.2 in /opt/conda/lib/python3.8/site-packages (0.16.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (4.1.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (2023.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.8/site-packages (from torch==2.1.2) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision==0.16.2) (1.23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision==0.16.2) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision==0.16.2) (9.0.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch==2.1.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision==0.16.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision==0.16.2) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision==0.16.2) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision==0.16.2) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch==2.1.2) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mPyTorch version: 2.1.2+cu121\n",
      "Torchvision version: 0.16.2+cu121\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade torch torchvision\n",
    "!pip install torch==2.1.2 torchvision==0.16.2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e60f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.cuda import amp\n",
    "from torch.nn.parameter import Parameter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import gc  \n",
    "from albumentations import (\n",
    "    Compose, Normalize, Resize,\n",
    "    RandomResizedCrop, HorizontalFlip,\n",
    "    RandomBrightnessContrast, ShiftScaleRotate\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import cv2\n",
    "import timm\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "sys.path.append('../tools')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd592c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# Use a chosen seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1fc9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set PyTorch to use GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e1668",
   "metadata": {},
   "source": [
    "# 実験1.マルチクラス分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf1767-f715-4d50-b862-146fa108e2c2",
   "metadata": {},
   "source": [
    "## データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af2f17d-61d6-4d27-a1f4-fe74843e7231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: ../data/input/Hazelnut/train/good/o039.jpg to ../data/input/01_multiclass/train/Hazelnut/o039.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o043.jpg to ../data/input/01_multiclass/train/Hazelnut/o043.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o019.jpg to ../data/input/01_multiclass/train/Hazelnut/o019.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o010.jpg to ../data/input/01_multiclass/train/Hazelnut/o010.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o004.jpg to ../data/input/01_multiclass/train/Hazelnut/o004.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o038.jpg to ../data/input/01_multiclass/train/Hazelnut/o038.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o029.jpg to ../data/input/01_multiclass/train/Hazelnut/o029.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o009.jpg to ../data/input/01_multiclass/train/Hazelnut/o009.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o011.jpg to ../data/input/01_multiclass/train/Hazelnut/o011.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o026.jpg to ../data/input/01_multiclass/train/Hazelnut/o026.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o015.jpg to ../data/input/01_multiclass/train/Hazelnut/o015.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o023.jpg to ../data/input/01_multiclass/train/Hazelnut/o023.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o031.jpg to ../data/input/01_multiclass/train/Hazelnut/o031.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o047.jpg to ../data/input/01_multiclass/train/Hazelnut/o047.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o034.jpg to ../data/input/01_multiclass/train/Hazelnut/o034.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o024.jpg to ../data/input/01_multiclass/train/Hazelnut/o024.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o044.jpg to ../data/input/01_multiclass/train/Hazelnut/o044.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o001.jpg to ../data/input/01_multiclass/train/Hazelnut/o001.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o014.jpg to ../data/input/01_multiclass/train/Hazelnut/o014.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o050.jpg to ../data/input/01_multiclass/train/Hazelnut/o050.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o046.jpg to ../data/input/01_multiclass/train/Hazelnut/o046.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o033.jpg to ../data/input/01_multiclass/train/Hazelnut/o033.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o037.jpg to ../data/input/01_multiclass/train/Hazelnut/o037.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o007.jpg to ../data/input/01_multiclass/train/Hazelnut/o007.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o025.jpg to ../data/input/01_multiclass/train/Hazelnut/o025.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o006.jpg to ../data/input/01_multiclass/train/Hazelnut/o006.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o042.jpg to ../data/input/01_multiclass/train/Hazelnut/o042.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o002.jpg to ../data/input/01_multiclass/train/Hazelnut/o002.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o027.jpg to ../data/input/01_multiclass/train/Hazelnut/o027.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o018.jpg to ../data/input/01_multiclass/train/Hazelnut/o018.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o049.jpg to ../data/input/01_multiclass/train/Hazelnut/o049.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o008.jpg to ../data/input/01_multiclass/train/Hazelnut/o008.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o041.jpg to ../data/input/01_multiclass/train/Hazelnut/o041.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o040.jpg to ../data/input/01_multiclass/train/Hazelnut/o040.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o012.jpg to ../data/input/01_multiclass/train/Hazelnut/o012.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o017.jpg to ../data/input/01_multiclass/train/Hazelnut/o017.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o013.jpg to ../data/input/01_multiclass/train/Hazelnut/o013.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o005.jpg to ../data/input/01_multiclass/train/Hazelnut/o005.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o022.jpg to ../data/input/01_multiclass/train/Hazelnut/o022.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o030.jpg to ../data/input/01_multiclass/train/Hazelnut/o030.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o028.jpg to ../data/input/01_multiclass/train/Hazelnut/o028.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o035.jpg to ../data/input/01_multiclass/train/Hazelnut/o035.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o048.jpg to ../data/input/01_multiclass/train/Hazelnut/o048.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o032.jpg to ../data/input/01_multiclass/train/Hazelnut/o032.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o016.jpg to ../data/input/01_multiclass/train/Hazelnut/o016.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o021.jpg to ../data/input/01_multiclass/train/Hazelnut/o021.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o036.jpg to ../data/input/01_multiclass/train/Hazelnut/o036.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o003.jpg to ../data/input/01_multiclass/train/Hazelnut/o003.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o045.jpg to ../data/input/01_multiclass/train/Hazelnut/o045.jpg\n",
      "Copied: ../data/input/Hazelnut/train/good/o020.jpg to ../data/input/01_multiclass/train/Hazelnut/o020.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t008.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t008.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t038.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t038.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t033.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t033.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t035.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t035.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t034.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t034.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t002.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t002.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t040.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t040.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t032.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t032.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t025.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t025.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t044.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t044.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t022.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t022.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t015.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t015.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t012.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t012.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t036.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t036.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t005.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t005.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t050.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t050.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t014.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t014.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t010.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t010.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t043.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t043.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t006.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t006.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t018.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t018.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t037.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t037.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t049.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t049.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t039.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t039.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t024.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t024.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t046.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t046.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t030.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t030.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t003.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t003.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t020.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t020.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t007.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t007.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t009.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t009.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t031.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t031.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t017.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t017.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t029.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t029.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t019.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t019.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t023.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t023.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t041.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t041.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t047.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t047.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t027.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t027.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t042.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t042.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t013.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t013.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t021.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t021.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t004.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t004.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t028.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t028.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t011.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t011.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t045.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t045.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t016.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t016.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t026.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t026.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t001.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t001.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/train/good/t048.jpg to ../data/input/01_multiclass/train/Rotary_beacon_light/t048.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_010.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_010.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_050.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_050.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_047.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_047.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_024.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_024.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_008.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_008.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_043.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_043.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_026.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_026.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_046.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_046.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_033.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_033.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_023.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_023.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_003.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_003.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_006.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_006.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_029.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_029.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_045.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_045.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_042.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_042.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_015.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_015.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_022.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_022.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_032.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_032.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_021.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_021.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_035.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_035.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_005.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_005.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_009.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_009.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_027.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_027.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_044.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_044.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_004.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_004.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_028.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_028.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_048.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_048.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_011.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_011.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_038.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_038.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_025.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_025.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_007.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_007.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_049.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_049.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_040.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_040.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_014.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_014.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_002.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_002.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_037.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_037.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_018.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_018.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_030.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_030.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_031.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_031.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_001.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_001.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_020.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_020.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_013.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_013.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_016.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_016.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_012.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_012.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_034.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_034.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_039.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_039.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_036.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_036.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_017.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_017.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_041.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_041.jpg\n",
      "Copied: ../data/input/Coffee_beans/train/good/good_019.jpg to ../data/input/01_multiclass/train/Coffee_beans/good_019.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/candy/NG_candy_004.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_candy_004.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/candy/NG_candy_002.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_candy_002.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/candy/NG_candy_005.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_candy_005.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/candy/NG_candy_003.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_candy_003.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/candy/NG_candy_001.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_candy_001.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_015.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_015.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_004.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_004.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_003.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_003.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_014.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_014.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_013.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_013.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_006.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_006.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_010.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_010.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_002.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_002.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_009.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_009.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_005.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_005.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_011.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_011.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_008.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_008.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_012.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_012.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_001.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_001.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/chocolate/NG_chocolate_007.jpg to ../data/input/01_multiclass/test/Coffee_beans_abn/NG_chocolate_007.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_017.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_017.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_008.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_008.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_005.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_005.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_003.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_003.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_011.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_011.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_010.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_010.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_015.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_015.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_016.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_016.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_018.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_018.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_013.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_013.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_009.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_009.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_006.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_006.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_001.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_001.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_002.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_002.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_007.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_007.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_019.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_019.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_012.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_012.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_020.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_020.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_004.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_004.jpg\n",
      "Copied: ../data/input/Coffee_beans/test/good/OK_good_014.jpg to ../data/input/01_multiclass/test/Coffee_beans_good/OK_good_014.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn004.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn004.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn010.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn010.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn012.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn012.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn008.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn008.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn001.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn001.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn015.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn015.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn013.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn013.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn005.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn005.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn006.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn006.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn007.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn007.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn009.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn009.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn003.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn003.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn011.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn011.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn002.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn002.jpg\n",
      "Copied: ../data/input/Hazelnut/test/crack/tn014.jpg to ../data/input/01_multiclass/test/Hazelnut_abn/tn014.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to005.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to005.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to023.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to023.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to007.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to007.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to009.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to009.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to022.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to022.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to017.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to017.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to001.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to001.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to002.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to002.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to021.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to021.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to006.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to006.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to003.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to003.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to013.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to013.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to016.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to016.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to010.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to010.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to011.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to011.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to004.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to004.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to020.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to020.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to014.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to014.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to018.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to018.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to015.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to015.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to019.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to019.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to008.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to008.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to025.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to025.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to024.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to024.jpg\n",
      "Copied: ../data/input/Hazelnut/test/good/to012.jpg to ../data/input/01_multiclass/test/Hazelnut_good/to012.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o019.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o019.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o010.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o010.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o004.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o004.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o009.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o009.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o011.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o011.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o015.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o015.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o001.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o001.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o014.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o014.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o007.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o007.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o006.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o006.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o002.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o002.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o018.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o018.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o008.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o008.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o012.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o012.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o017.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o017.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o013.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o013.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o005.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o005.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o016.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o016.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o003.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o003.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/good/o020.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_good/o020.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n019.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn019.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n008.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn008.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n009.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn009.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n006.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn006.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n014.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn014.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n012.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn012.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n003.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn003.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n010.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn010.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n013.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn013.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n015.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn015.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n007.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn007.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n017.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn017.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n004.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn004.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n016.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn016.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n002.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn002.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n001.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn001.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n005.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn005.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n011.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn011.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n020.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn020.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/nocolor/n018.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/nocolorn018.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n019.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn019.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n008.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn008.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n009.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn009.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n006.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn006.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n014.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn014.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n012.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn012.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n003.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn003.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n010.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn010.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n013.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn013.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n015.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn015.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n007.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn007.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n017.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn017.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n004.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn004.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n016.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn016.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n002.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn002.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n001.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn001.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n005.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn005.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n011.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn011.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n020.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn020.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/red/n018.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/redn018.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n019.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown019.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n008.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown008.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n009.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown009.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n006.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown006.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n014.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown014.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n012.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown012.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n003.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown003.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n010.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown010.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n013.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown013.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n015.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown015.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n007.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown007.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n017.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown017.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n004.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown004.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n016.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown016.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n002.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown002.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n001.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown001.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n005.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown005.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n011.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown011.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n020.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown020.jpg\n",
      "Copied: ../data/input/Rotary_beacon_light/test/yellow/n018.jpg to ../data/input/01_multiclass/test/Rotary_beacon_light_abn/yellown018.jpg\n"
     ]
    }
   ],
   "source": [
    "# 必要なディレクトリ構成に変更\n",
    "\n",
    "copy_images('../data/input/Hazelnut/train/good/','../data/input/01_multiclass/train/Hazelnut/')\n",
    "copy_images('../data/input/Rotary_beacon_light/train/good/','../data/input/01_multiclass/train/Rotary_beacon_light/')\n",
    "copy_images('../data/input/Coffee_beans/train/good/','../data/input/01_multiclass/train/Coffee_beans/')\n",
    "\n",
    "copy_images('../data/input/Coffee_beans/test/candy/','../data/input/01_multiclass/test/Coffee_beans_abn/')\n",
    "copy_images('../data/input/Coffee_beans/test/chocolate/','../data/input/01_multiclass/test/Coffee_beans_abn/')\n",
    "copy_images('../data/input/Coffee_beans/test/good/','../data/input/01_multiclass/test/Coffee_beans_good/')\n",
    "\n",
    "copy_images('../data/input/Hazelnut/test/crack/','../data/input/01_multiclass/test/Hazelnut_abn/')\n",
    "copy_images('../data/input/Hazelnut/test/good/','../data/input/01_multiclass/test/Hazelnut_good/')\n",
    "\n",
    "copy_images('../data/input/Rotary_beacon_light/test/good/','../data/input/01_multiclass/test/Rotary_beacon_light_good/')\n",
    "copy_images('../data/input/Rotary_beacon_light/test/nocolor/','../data/input/01_multiclass/test/Rotary_beacon_light_abn/',prefix='nocolor')\n",
    "copy_images('../data/input/Rotary_beacon_light/test/red/','../data/input/01_multiclass/test/Rotary_beacon_light_abn/',prefix='red')\n",
    "copy_images('../data/input/Rotary_beacon_light/test/yellow/','../data/input/01_multiclass/test/Rotary_beacon_light_abn/',prefix='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0606e",
   "metadata": {},
   "source": [
    "## 学習フェーズ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0add230",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40532d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(\n",
    "        x.clamp(min=eps).pow(p),\n",
    "        (x.size(-2), x.size(-1))\n",
    "    ).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(\n",
    "            self.p.data.tolist()[0]\n",
    "        ) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "    \n",
    "class ArcMarginProduct(nn.Module):\n",
    "    \"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=64.0, m=1.0, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        input = input.float()\n",
    "\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        one_hot = torch.zeros(cosine.size(), device=device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class AngularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes=2515, model_name=\"resnet34\", pooling=\"GeM\",\n",
    "                 margin=0.3, scale=30, fc_dim=512,\n",
    "                 pretrained=True, loss_kwargs=None):\n",
    "        super(AngularModel, self).__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "        )\n",
    "        final_in_features = self.backbone.fc.in_features\n",
    "\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "\n",
    "        loss_kwargs = loss_kwargs or {\n",
    "            \"s\": scale,\n",
    "            \"m\": margin,\n",
    "            \"easy_margin\": False,\n",
    "            \"ls_eps\": 0.0,\n",
    "        }\n",
    "\n",
    "        self.pooling = GeM()\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "\n",
    "        self.final = ArcMarginProduct(fc_dim,\n",
    "                                      n_classes,\n",
    "                                      **loss_kwargs)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        feature = self.extract_features(x)\n",
    "        logits = self.final(feature, label)\n",
    "        return logits\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        # fc\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, n_classes=2515, model_name=\"resnet34\", fc_dim=512, pretrained=True):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # バックボーンの初期化\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        final_in_features = self.backbone.fc.in_features\n",
    "\n",
    "        # バックボーンの最終層を除去\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "\n",
    "        # グローバル平均プーリングと全結合層の追加\n",
    "        self.pooling = GeM()\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.classifier = nn.Linear(fc_dim, n_classes)\n",
    "\n",
    "        self._init_params()\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.constant_(self.classifier.bias, 0)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        feature = self.extract_features(x)\n",
    "        x = self.relu(feature)\n",
    "\n",
    "        # 分類器\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        # fc\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def get_transforms():\n",
    "    transforms_dict = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(512),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "    }\n",
    "    return transforms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb58f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloaders, model, criterion, optimizer, num_epochs, file_name):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            \n",
    "            # tqdmを追加して、ループの進捗を表示\n",
    "            for inputs, labels in tqdm(dataloaders[phase], desc=f\"{phase} epoch {epoch+1}\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                correct_predictions += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = correct_predictions.double() / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    torch.save(model.state_dict(), f'../models/{file_name}.pth')\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635739a2",
   "metadata": {},
   "source": [
    "## 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86a7bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(root_dir, transforms_dict):\n",
    "    datasets = {\n",
    "        'train': torchvision.datasets.ImageFolder(root=root_dir, transform=transforms_dict['train']),\n",
    "        # 'test': torchvision.datasets.ImageFolder(root=root_dir, transform=transforms_dict['valid']),\n",
    "    }\n",
    "    return datasets\n",
    "\n",
    "def get_dataloaders(datasets, batch_size):\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(datasets['train'], batch_size=batch_size, shuffle=True),\n",
    "        # 'test': DataLoader(datasets['test'], batch_size=batch_size, shuffle=False),\n",
    "    }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b22b0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1: 100%|██████████| 5/5 [00:07<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 9.1740 Acc: 0.0000\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 2: 100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 5.7524 Acc: 0.0200\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 3: 100%|██████████| 5/5 [00:06<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.0542 Acc: 0.4133\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 4: 100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7152 Acc: 0.7600\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 5: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5306 Acc: 0.8533\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 6: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2270 Acc: 0.9333\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 7: 100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3207 Acc: 0.9133\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 8: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1327 Acc: 0.9600\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 9: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1286 Acc: 0.9667\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 10: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0232 Acc: 0.9933\n",
      "Finished Training\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.2336 Acc: 0.3267\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 2: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7190 Acc: 0.7067\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 3: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4061 Acc: 0.9133\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 4: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2045 Acc: 0.9600\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 5: 100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1506 Acc: 0.9867\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 6: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0970 Acc: 0.9867\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 7: 100%|██████████| 5/5 [00:06<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0982 Acc: 0.9933\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 8: 100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0547 Acc: 0.9933\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 9: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0599 Acc: 0.9933\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 10: 100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0479 Acc: 1.0000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Get transforms\n",
    "transforms_dict = get_transforms()\n",
    "\n",
    "# Load datasets\n",
    "datasets = load_datasets(root_dir='../data/input/01_multiclass/train/', transforms_dict=transforms_dict)\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = get_dataloaders(datasets, batch_size=32)\n",
    "\n",
    "# Define model\n",
    "n_classes = 3\n",
    "arcmodel = AngularModel(n_classes=n_classes)\n",
    "arcmodel = arcmodel.to(device)\n",
    "\n",
    "cnnmodel = CNNModel(n_classes=n_classes)\n",
    "cnnmodel = cnnmodel.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "arc_optimizer = optim.SGD(arcmodel.parameters(), lr=0.001, momentum=0.9)\n",
    "cnn_optimizer = optim.SGD(cnnmodel.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "train_model(dataloaders, arcmodel, criterion, arc_optimizer, num_epochs=10, file_name='angularmodel')\n",
    "train_model(dataloaders, cnnmodel, criterion, cnn_optimizer, num_epochs=10, file_name='cnnmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188aaeb",
   "metadata": {},
   "source": [
    "## 予測フェーズ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428400f",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6c456bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vectors(model, dataloader, out_dim, device):\n",
    "    with torch.no_grad():\n",
    "        vecs = torch.zeros(out_dim, len(dataloader.dataset)).to(device)\n",
    "        labels = []\n",
    "        for i, (images, lbls) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            vecs[:, i] =  model.extract_features(images).squeeze()\n",
    "            labels.extend(lbls.numpy())\n",
    "        return vecs, labels\n",
    "\n",
    "# 新しいラベルの割り当て\n",
    "def reassign_labels(class_to_idx):\n",
    "    new_labels = {}\n",
    "    for class_name, label in class_to_idx.items():\n",
    "        if '_good' in class_name:\n",
    "            new_labels[label] = 0\n",
    "        elif '_abn' in class_name:\n",
    "            new_labels[label] = 1\n",
    "    return new_labels\n",
    "\n",
    "def main(path, model,input_size=512, out_dim=512, ):\n",
    "    \n",
    "    # model = AngularModel(n_classes=n_classes)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    \n",
    "    transforms_dict = get_transforms()\n",
    "\n",
    "    # Define the ImageFolder datasets for index and query images\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root='../data/input/01_multiclass/train/', transform=transforms_dict['valid'])\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root='../data/input/01_multiclass/test/', transform=transforms_dict['valid'])\n",
    "    \n",
    "    # Define the DataLoaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Extract vectors\n",
    "    train_vectors, train_labels = extract_vectors(model, train_dataloader, out_dim, device=device)\n",
    "    test_vectors, test_labels = extract_vectors(model, test_dataloader, out_dim, device=device)\n",
    "\n",
    "    # Convert vectors to numpy\n",
    "    train_vectors = train_vectors.cpu().numpy()\n",
    "    test_vectors = test_vectors.cpu().numpy()\n",
    "\n",
    "    # 距離計算\n",
    "    distances = cdist(test_vectors.T, train_vectors.T, 'cosine')\n",
    "    distance_j = np.min(distances, axis=1)\n",
    "\n",
    "    # ラベルを新しい値に変更\n",
    "    new_class_to_idx = reassign_labels(class_to_idx) #'*_good'のlabel値(eg.0)に対して新しいlabel値 0を割り当て\n",
    "    new_test_labels = [new_class_to_idx[label] for label in test_labels]\n",
    "\n",
    "    auc_score = roc_auc_score(new_test_labels, distance_j)\n",
    "    print('auc score: ', auc_score)\n",
    "    # return train_vectors, train_labels, test_vectors, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa24eb5",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f83aa3-859d-4d92-880e-f563c9993a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !find ../data/input/ -name .ipynb_checkpoints -type d -exec rm -rf {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17dd1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■arcfaceによる推論結果\n",
      "auc score:  0.9331174089068827\n",
      "■CNNによる推論結果\n",
      "auc score:  0.9072064777327935\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = {\n",
    "    'Coffee_beans_abn': 0, 'Coffee_beans_good': 1, 'Hazelnut_abn': 2,\n",
    "    'Hazelnut_good': 3, 'Rotary_beacon_light_abn': 4, 'Rotary_beacon_light_good': 5\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_classes=3\n",
    "    arcmodel = AngularModel(n_classes=n_classes)\n",
    "    cnnmodel = CNNModel(n_classes=n_classes)\n",
    "\n",
    "    print('■arcfaceによる推論結果')\n",
    "    main(path='../models/angularmodel.pth', model=arcmodel)\n",
    "    print('■CNNによる推論結果')\n",
    "    main(path='../models/cnnmodel.pth', model=cnnmodel)\n",
    "\n",
    "# print('train ',arc_train_vectors.shape, len(arc_train_labels))\n",
    "# print('test: ',arc_test_vectors.shape, len(arc_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66822eb0-f003-49b6-b4f9-f8b9c01fbef0",
   "metadata": {},
   "source": [
    "## grad-camによるモデル判断根拠を可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93886f2e-1649-49cf-bf93-edde2e635583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grad-cam\n",
      "  Downloading grad-cam-1.5.0.tar.gz (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from grad-cam) (1.23.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from grad-cam) (9.0.1)\n",
      "Requirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.8/site-packages (from grad-cam) (2.1.2)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.8/site-packages (from grad-cam) (0.16.2)\n",
      "Collecting ttach (from grad-cam)\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from grad-cam) (4.62.3)\n",
      "Collecting opencv-python (from grad-cam)\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from grad-cam) (3.7.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from grad-cam) (1.3.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (4.1.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (2023.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.1->grad-cam) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.1->grad-cam) (12.3.101)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision>=0.8.2->grad-cam) (2.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->grad-cam) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->grad-cam) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->grad-cam) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->grad-cam) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->grad-cam) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->grad-cam) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->grad-cam) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->grad-cam) (6.1.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->grad-cam) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->grad-cam) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->grad-cam) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->grad-cam) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision>=0.8.2->grad-cam) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision>=0.8.2->grad-cam) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision>=0.8.2->grad-cam) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision>=0.8.2->grad-cam) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\n",
      "Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: grad-cam\n",
      "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grad-cam: filename=grad_cam-1.5.0-py3-none-any.whl size=38070 sha256=7e75b376ee7be3c752728813b265d813664dfe97d1a15d797a75b3f4c538cd22\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/fa/42/c0/201f854a89e14b4e7235cf0e5e0809dbdf3ae4f348e882405d\n",
      "Successfully built grad-cam\n",
      "Installing collected packages: ttach, opencv-python, grad-cam\n",
      "Successfully installed grad-cam-1.5.0 opencv-python-4.8.1.78 ttach-0.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a1c41a2-f5aa-4de5-a675-304bec2498b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam import GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2acfe069-125c-4113-bdb8-046e25d76779",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cc9123b6e37b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# input_img = input_transform(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_transform' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root='../data/input/01_multiclass/train/', transform=transforms_dict['valid'])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "img, label = train_dataset[60]\n",
    "# input_img = input_transform(img)\n",
    "# img = img_transform(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e283e9c2-6455-4294-af1d-9f4dd699b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473],\n",
       "         [-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473],\n",
       "         [-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473],\n",
       "         ...,\n",
       "         [-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473],\n",
       "         [-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473],\n",
       "         [-1.3473, -1.3473, -1.3473,  ..., -1.3473, -1.3473, -1.3473]],\n",
       "\n",
       "        [[-1.2479, -1.2479, -1.2479,  ..., -1.2479, -1.2479, -1.2479],\n",
       "         [-1.2479, -1.2479, -1.2479,  ..., -1.2479, -1.2479, -1.2479],\n",
       "         [-1.2479, -1.2479, -1.2479,  ..., -1.2479, -1.2479, -1.2479],\n",
       "         ...,\n",
       "         [-1.2479, -1.2479, -1.2479,  ..., -1.2479, -1.2479, -1.2479],\n",
       "         [-1.2479, -1.2479, -1.2479,  ..., -1.2479, -1.2479, -1.2479],\n",
       "         [-1.2479, -1.2479, -1.2479,  ..., -1.2479, -1.2479, -1.2479]],\n",
       "\n",
       "        [[-1.0201, -1.0201, -1.0201,  ..., -1.0201, -1.0201, -1.0201],\n",
       "         [-1.0201, -1.0201, -1.0201,  ..., -1.0201, -1.0201, -1.0201],\n",
       "         [-1.0201, -1.0201, -1.0201,  ..., -1.0201, -1.0201, -1.0201],\n",
       "         ...,\n",
       "         [-1.0201, -1.0201, -1.0201,  ..., -1.0201, -1.0201, -1.0201],\n",
       "         [-1.0201, -1.0201, -1.0201,  ..., -1.0201, -1.0201, -1.0201],\n",
       "         [-1.0201, -1.0201, -1.0201,  ..., -1.0201, -1.0201, -1.0201]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41ff73b5-597b-4ab5-a229-f55616d09f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AngularModel(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooling): GeM(p=2.9576, eps=1e-06)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final): ArcMarginProduct()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes=3\n",
    "model = AngularModel(n_classes=n_classes)\n",
    "# model = AngularModel(n_classes=n_classes)\n",
    "model.load_state_dict(torch.load('../models/angularmodel.pth'))\n",
    "# model.to(device)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059cc0d-5bbf-4bdc-9195-bc96058897f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    実装途中\n",
    "'''\n",
    "\n",
    "# target_layers = [model.backbone[-3]]\n",
    "# cam = GradCAM(\n",
    "#     model=model, target_layers=target_layers, use_cuda=torch.cuda.is_available()\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
